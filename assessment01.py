# -*- coding: utf-8 -*-
"""assessment01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c7VNYxjSQFCIDjfPru2RzBmkKiuc9zVP
"""

#import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#load datasets
train = pd.read_csv('/content/train_LZdllcl (1).csv')
test = pd.read_csv('/content/test_2umaH9m (1).csv')

#view of data
train.head()

train.shape

train.info()

train['department'].unique()

train['department'].value_counts()

train['region'].value_counts()

train['education'].value_counts()

train['recruitment_channel'].value_counts()

#copying train to traindata
traindata = train.copy()

test.head()

#copying test to testdata
testdata = test.copy()

"""preprocessing on traindata"""

#checking duplication
traindata.duplicated().sum()

#checking for missing values
traindata.isnull().sum()

traindata['education'].mode()

# Impute 'education' column with mode value
traindata['education'] = traindata['education'].fillna(traindata['education'].mode()[0])

# Impute 'previous_year_rating',gender,recruitment_channel,no_of_trainings,age,length_of_service,KPIs_met >80%,awards_won?,avg_training_score,is_promoted column with median value
traindata['previous_year_rating'] = traindata['previous_year_rating'].fillna(traindata['previous_year_rating'].median())
traindata['region'] = traindata['region'].fillna(traindata['region'].mode()[0])
traindata['gender'] = traindata['gender'].fillna(traindata['gender'].mode()[0])
traindata['recruitment_channel'] = traindata['recruitment_channel'].fillna(traindata['recruitment_channel'].mode()[0])
traindata['no_of_trainings'] =  traindata['no_of_trainings'].fillna(traindata['no_of_trainings'].mode()[0])
traindata['age'] = traindata['age'].fillna(traindata['age'].mode()[0])

traindata.isna().sum()

#impute length_of_service	,KPIs_met >80%,awards_won?,avg_training_score	,is_promoted with median values
traindata['length_of_service'] = traindata['length_of_service'].fillna(traindata['length_of_service'].median())
traindata['KPIs_met >80%'] = traindata['KPIs_met >80%'].fillna(traindata['KPIs_met >80%'].median())
traindata['awards_won?'] = traindata['awards_won?'].fillna(traindata['awards_won?'].median())
traindata['avg_training_score'] = traindata['avg_training_score'].fillna(traindata['avg_training_score'].median())
traindata['is_promoted'] = traindata['is_promoted'].fillna(traindata['is_promoted'].median())

#boxplot for traindata
plt.figure(figsize=(15,6))
traindata.boxplot()

#outliers showing in boxplot are not cosidering because it is meaningful.
#droping employeeid it has no meaning in processing
traindata.drop('employee_id',axis=1,inplace=True)

traindata.columns

# heatmap for numeric types
numerical_columns = traindata.select_dtypes(include=['number']).columns
corr = traindata[numerical_columns].corr()
sns.heatmap(corr, annot=True, cmap='summer');

"""from the above heatmap clear that avg training score,awards won,kpis met>80% & previous year rating are more correlated with target column(promoted or not).
similarly age and length of service are correlated each other this may leads to multicollinearity.may drop either.

Encoding
"""

#label encoding for department,region,education,gender,recriutment channel
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
traindata['department'] = le.fit_transform(traindata['department'])
traindata['region'] = le.fit_transform(traindata['region'])
traindata['education'] = le.fit_transform(traindata['education'])
traindata['gender'] = le.fit_transform(traindata['gender'])
traindata['recruitment_channel'] = le.fit_transform(traindata['recruitment_channel'])

traindata.dtypes

"""encoding completed.outliers are not checking and removing

"""

#copying test to testdata
testdata = test.copy()

"""Preprocessing of testdata"""

#check duplication
testdata.duplicated().sum()

#check null values
testdata.isna().sum()

# Impute 'education' column with mode value
testdata['education'] = testdata['education'].fillna(testdata['education'].mode()[0])

# Impute 'previous_year_rating' column with median value
testdata['previous_year_rating'] = testdata['previous_year_rating'].fillna(testdata['previous_year_rating'].median())

testdata.isna().sum()

testdata.info()

#label encoding for department,region,education,gender,recriutment channel
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
traindata['department'] = le.fit_transform(traindata['department'])
traindata['region'] = le.fit_transform(traindata['region'])
traindata['education'] = le.fit_transform(traindata['education'])
traindata['gender'] = le.fit_transform(traindata['gender'])
traindata['recruitment_channel'] = le.fit_transform(traindata['recruitment_channel'])

testdata.dtypes

"""CLASSIFICATION MODELS

1.Logistic Regression
"""

#libraries for logistic regression
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,confusion_matrix,f1_score

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import f1_score

#split train and test
x = traindata.drop('is_promoted',axis=1)
y = traindata['is_promoted']
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)

# logistic regression
log = LogisticRegression()

log.fit(x_train,y_train)

#predict target values for the test values
y_pred_log = log.predict(x_test)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_log)
print("Confusion Matrix:\n", cm)

# Accuracy Score
accuracy = accuracy_score(y_test, y_pred_log)
print(f'Accuracy_log: {accuracy:.2f}')

# F1 Score
f1 = f1_score(y_test, y_pred_log)
print(f'F1 Score_log: {f1:.2f}')

#after standard scaling

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train_sc = sc.fit_transform(x_train)
x_test_sc = sc.fit_transform(x_test)

model1 = LogisticRegression()
model1.fit(x_train_sc,y_train)

y_pred_log_sc = model1.predict(x_test_sc)

# Accuracy Score
accuracy = accuracy_score(y_test, y_pred_log_sc)
print(f'Accuracy_log_sc: {accuracy:.2f}')

# F1 Score
f1 = f1_score(y_test, y_pred_log_sc)
print(f'F1 Score_log_sc: {f1:.2f}')

"""2.KNN MODEL"""

#knn model
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(x_train,y_train)

metrik_k = []
neighbors = np.arange(3,15)
for k in neighbors:
  classifier = KNeighborsClassifier(n_neighbors=k)
  classifier.fit(x_train,y_train)
  y_pred_knn = classifier.predict(x_test)
  acc = accuracy_score(y_test,y_pred_knn)
  metrik_k.append(acc)

plt.plot(neighbors,metrik_k,'o-')
plt.xlabel('K value')
plt.ylabel('Accuracy')
plt.grid()
plt.show()

"""highest accuracy at k=9 so k taken as 9"""

classifier = KNeighborsClassifier(n_neighbors=9)
classifier.fit(x_train,y_train)

y_pred_knn = classifier.predict(x_test)
#print accuracy score and f1 score
print(f'Accuracy_knn: {accuracy_score(y_test,y_pred_knn):.2f}')
print(f'F1 Score_knn: {f1_score(y_test,y_pred_knn):.2f}')

"""3.SVM MODEL"""

#svm model
from sklearn.svm import SVC
#fitting to model
svm = SVC()
svm.fit(x_train,y_train)

y_pred_svm = svm.predict(x_test)
#printing accuracy score and f1 score
print("Accuracy Score_svm: ",accuracy_score(y_test,y_pred_svm))
print("F1 Score_svm: ",f1_score(y_test,y_pred_svm))

"""4.NAIVE BAYES ALGORITHM"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(x_train,y_train)
y_pred_gnb = gnb.predict(x_test)
#PRINT F1score and accuracy score
print("Accuracy Score_gnb: ",accuracy_score(y_test,y_pred_gnb))
print("F1 Score_gnb: ",f1_score(y_test,y_pred_gnb))

"""5.Decision tree classifier"""

from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(criterion = 'entropy')
clf.fit(x_train,y_train)
y_pred_dtree = clf.predict(x_test)
#print accuracy score and f1 score
print("Accuracy Score_dtree: ",accuracy_score(y_test,y_pred_dtree))
print("F1 Score_dtree: ",f1_score(y_test,y_pred_dtree))

"""6.Random forest algorithm"""

#random forest model
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=100)
rfc.fit(x_train,y_train)
y_pred_rfc = rfc.predict(x_test)
#print accuracy score and f1score
print("Accuracy Score_rfc: ",accuracy_score(y_test,y_pred_rfc))
print("F1 Score_rfc: ",f1_score(y_test,y_pred_rfc))
f1_rfc=f1_score(y_test,y_pred_rfc)

f1_log=f1_score(y_test, y_pred_log)
f1_knn=f1_score(y_test, y_pred_knn)
f1_svm=f1_score(y_test, y_pred_svm)
f1_gnb=f1_score(y_test, y_pred_gnb)
f1_dtree=f1_score(y_test, y_pred_dtree)

#list of models and their f1 scores
model_scores = [
    ('Logistic Regression', f1_log),
    ('KNN', f1_knn),
    ('SVM', f1_svm),
    ('Naive Bayes', f1_gnb),
    ('Decision Tree', f1_dtree),
    ('Random Forest', f1_rfc)
]

model_scores

"""Random forest has better f1 value

Crossvalidation and hyperparametertuning
"""

from sklearn.model_selection import cross_val_score

cv_res_gnb = cross_val_score(gnb,x,y,cv=5)
cv_res_rfc = cross_val_score(rfc,x,y,cv=5)
cv_res_dtree = cross_val_score(clf,x,y,cv=5)
cv_res_svm = cross_val_score(svm,x,y,cv=5)
cv_res_knn = cross_val_score(knn,x,y,cv=5)

cv_res_gnb
cv_res_rfc
cv_res_dtree
cv_res_svm
cv_res_knn

"""Testdata"""

testdata.sample(4)

#label encoding for department,region,education,gender,recriutment channel
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
testdata['department'] = le.fit_transform(testdata['department'])
testdata['region'] = le.fit_transform(testdata['region'])
testdata['education'] = le.fit_transform(testdata['education'])
testdata['gender'] = le.fit_transform(testdata['gender'])
testdata['recruitment_channel'] = le.fit_transform(testdata['recruitment_channel'])

testdata.head()

predictions = rfc.predict(testdata.drop('employee_id', axis=1))

"""fitting best model on test data"""

# Convert predictions to a DataFrame
predictions_df = pd.DataFrame(predictions, columns=['Predicted'])

# Display a random sample of 5 predictions
predictions_df.sample(5)

#combine predictions with test data
test_df = pd.concat([testdata, predictions_df], axis=1)
test_df.sample(5)

test_df.to_csv('predictions.csv', index=False)
from google.colab import files
files.download('predictions.csv')